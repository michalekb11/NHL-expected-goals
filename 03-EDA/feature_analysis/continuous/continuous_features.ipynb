{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from scipy.stats import spearmanr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from feature_functions import spearman_rank, boxplot, density_plot, diff_in_means, diff_in_medians\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the engine to connect to the MySQL database\n",
    "engine = sqlalchemy.create_engine('mysql+mysqlconnector://root:root@localhost/nhl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing each query separately runs a lot faster...\n",
    "# Skater query list\n",
    "skater_games_query = \"\"\"\n",
    "SELECT player_id,\n",
    "    opponent,\n",
    "    date,\n",
    "    G\n",
    "FROM skater_games\n",
    "\"\"\"\n",
    "\n",
    "point_streak_query = \"\"\"\n",
    "SELECT * \n",
    "FROM point_streak\n",
    "\"\"\"\n",
    "\n",
    "s_rolling3_query = \"\"\"\n",
    "SELECT * \n",
    "FROM skater_per60_rolling3\n",
    "\"\"\"\n",
    "\n",
    "s_rolling5_query = \"\"\"\n",
    "SELECT * \n",
    "FROM skater_per60_rolling5\n",
    "\"\"\"\n",
    "\n",
    "s_rolling10_query = \"\"\"\n",
    "SELECT * \n",
    "FROM skater_per60_rolling10\n",
    "\"\"\"\n",
    "\n",
    "s_rolling15_query = \"\"\"\n",
    "SELECT * \n",
    "FROM skater_per60_rolling15\n",
    "\"\"\"\n",
    "\n",
    "s_rolling20_query = \"\"\"\n",
    "SELECT * \n",
    "FROM skater_per60_rolling20\n",
    "\"\"\"\n",
    "\n",
    "s_query_list = [skater_games_query, s_rolling3_query, s_rolling5_query, s_rolling10_query, s_rolling15_query, s_rolling20_query, point_streak_query]\n",
    "\n",
    "# Goalie query list\n",
    "g_assigned_query = \"\"\"\n",
    "SELECT *\n",
    "FROM assigned_goalie\n",
    "\"\"\"\n",
    "\n",
    "g_rolling3_query = \"\"\"\n",
    "SELECT * \n",
    "FROM goalie_per60_rolling3\n",
    "\"\"\"\n",
    "\n",
    "g_rolling5_query = \"\"\"\n",
    "SELECT * \n",
    "FROM goalie_per60_rolling5\n",
    "\"\"\"\n",
    "\n",
    "g_rolling10_query = \"\"\"\n",
    "SELECT * \n",
    "FROM goalie_per60_rolling10\n",
    "\"\"\"\n",
    "\n",
    "g_rolling15_query = \"\"\"\n",
    "SELECT * \n",
    "FROM goalie_per60_rolling15\n",
    "\"\"\"\n",
    "\n",
    "g_rolling20_query = \"\"\"\n",
    "SELECT * \n",
    "FROM goalie_per60_rolling20\n",
    "\"\"\"\n",
    "\n",
    "g_query_list = [g_assigned_query, g_rolling3_query, g_rolling5_query, g_rolling10_query, g_rolling15_query, g_rolling20_query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run each query separately, then merge later for time purposes...\n",
    "s_df_list = [pd.read_sql(q,  con=engine) for q in s_query_list]\n",
    "\n",
    "# Time = 8 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run each query separately, then merge later for time purposes...\n",
    "g_df_list = [pd.read_sql(q, con=engine) for q in g_query_list]\n",
    "\n",
    "# Time = 1 second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all skater features on player_id, date\n",
    "s_df = reduce(lambda x, y: pd.merge(x,  y, how='left', on=['player_id', 'date']), s_df_list)\n",
    "\n",
    "# Merge all goalie features on player_id, date\n",
    "g_df = reduce(lambda x, y: pd.merge(x,  y, how='left', on=['player_id', 'date']), g_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge skater df with goalie df on opponent == team, date\n",
    "features = pd.merge(s_df, g_df, how='left', left_on=['opponent', 'date'], right_on=['team', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125637, 127)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#master_query = \"\"\"\n",
    "SELECT a.player_id,\n",
    "    a.date,\n",
    "    a.G,\n",
    "    b.*,\n",
    "    c.*,\n",
    "    d.*,\n",
    "    e.*,\n",
    "    f.*,\n",
    "    g.*\n",
    "FROM skater_games a\n",
    "LEFT JOIN skater_per60_rolling3 b\n",
    "    ON a.player_id = b.player_id AND a.date = b.date\n",
    "LEFT JOIN skater_per60_rolling5 c\n",
    "    ON a.player_id = c.player_id AND a.date = c.date\n",
    "LEFT JOIN skater_per60_rolling10 d\n",
    "    ON a.player_id = d.player_id AND a.date = d.date\n",
    "LEFT JOIN skater_per60_rolling15 e\n",
    "    ON a.player_id = e.player_id AND a.date = e.date\n",
    "LEFT JOIN skater_per60_rolling20 f\n",
    "    ON a.player_id = f.player_id AND a.date = f.date\n",
    "LEFT JOIN point_streak g\n",
    "    ON a.player_id = g.player_id AND a.date = g.date\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all features at once\n",
    "# features = pd.read_sql(master_query, con=engine)\n",
    "\n",
    "# Read in just rolling 3 for testing\n",
    "#features = pd.read_sql(per60_3_query, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num rows: 125637\n",
      "Num columns: 127\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_id_x</th>\n",
       "      <th>opponent</th>\n",
       "      <th>date</th>\n",
       "      <th>G</th>\n",
       "      <th>G60_3</th>\n",
       "      <th>A60_3</th>\n",
       "      <th>P60_3</th>\n",
       "      <th>rating60_3</th>\n",
       "      <th>PIM60_3</th>\n",
       "      <th>EVG60_3</th>\n",
       "      <th>...</th>\n",
       "      <th>GA60_15</th>\n",
       "      <th>SA60_15</th>\n",
       "      <th>SV60_15</th>\n",
       "      <th>SVpct_15</th>\n",
       "      <th>avgTOI_15_y</th>\n",
       "      <th>GA60_20</th>\n",
       "      <th>SA60_20</th>\n",
       "      <th>SV60_20</th>\n",
       "      <th>SVpct_20</th>\n",
       "      <th>avgTOI_20_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/a/abramvi01</td>\n",
       "      <td>MTL</td>\n",
       "      <td>2021-05-05</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.737591</td>\n",
       "      <td>27.786548</td>\n",
       "      <td>25.048957</td>\n",
       "      <td>0.901478</td>\n",
       "      <td>58.445547</td>\n",
       "      <td>2.736025</td>\n",
       "      <td>28.018920</td>\n",
       "      <td>25.282896</td>\n",
       "      <td>0.902351</td>\n",
       "      <td>59.209990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/a/abramvi01</td>\n",
       "      <td>WPG</td>\n",
       "      <td>2021-05-08</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.688031</td>\n",
       "      <td>30.004239</td>\n",
       "      <td>27.316208</td>\n",
       "      <td>0.910412</td>\n",
       "      <td>55.058887</td>\n",
       "      <td>2.453842</td>\n",
       "      <td>30.566341</td>\n",
       "      <td>28.112499</td>\n",
       "      <td>0.919721</td>\n",
       "      <td>56.238330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/a/abruzni01</td>\n",
       "      <td>PHI</td>\n",
       "      <td>2022-04-02</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.348027</td>\n",
       "      <td>34.819478</td>\n",
       "      <td>31.471451</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>59.736680</td>\n",
       "      <td>3.161741</td>\n",
       "      <td>33.555256</td>\n",
       "      <td>30.393514</td>\n",
       "      <td>0.905775</td>\n",
       "      <td>58.828340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/a/abruzni01</td>\n",
       "      <td>TBL</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.620087</td>\n",
       "      <td>30.097410</td>\n",
       "      <td>27.477323</td>\n",
       "      <td>0.912946</td>\n",
       "      <td>59.540007</td>\n",
       "      <td>2.555430</td>\n",
       "      <td>30.113990</td>\n",
       "      <td>27.558560</td>\n",
       "      <td>0.915141</td>\n",
       "      <td>59.872505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/a/abruzni01</td>\n",
       "      <td>DAL</td>\n",
       "      <td>2022-04-07</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.250283</td>\n",
       "      <td>37.689454</td>\n",
       "      <td>34.439171</td>\n",
       "      <td>0.913761</td>\n",
       "      <td>57.841113</td>\n",
       "      <td>3.449657</td>\n",
       "      <td>35.989704</td>\n",
       "      <td>32.540047</td>\n",
       "      <td>0.904149</td>\n",
       "      <td>58.266665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    player_id_x opponent        date  G  G60_3  A60_3  P60_3  rating60_3   \n",
       "0  /a/abramvi01      MTL  2021-05-05  0    NaN    NaN    NaN         NaN  \\\n",
       "1  /a/abramvi01      WPG  2021-05-08  0    NaN    NaN    NaN         NaN   \n",
       "2  /a/abruzni01      PHI  2022-04-02  0    NaN    NaN    NaN         NaN   \n",
       "3  /a/abruzni01      TBL  2022-04-04  0    NaN    NaN    NaN         NaN   \n",
       "4  /a/abruzni01      DAL  2022-04-07  0    NaN    NaN    NaN         NaN   \n",
       "\n",
       "   PIM60_3  EVG60_3  ...   GA60_15    SA60_15    SV60_15  SVpct_15   \n",
       "0      NaN      NaN  ...  2.737591  27.786548  25.048957  0.901478  \\\n",
       "1      NaN      NaN  ...  2.688031  30.004239  27.316208  0.910412   \n",
       "2      NaN      NaN  ...  3.348027  34.819478  31.471451  0.903846   \n",
       "3      NaN      NaN  ...  2.620087  30.097410  27.477323  0.912946   \n",
       "4      NaN      NaN  ...  3.250283  37.689454  34.439171  0.913761   \n",
       "\n",
       "   avgTOI_15_y   GA60_20    SA60_20    SV60_20  SVpct_20  avgTOI_20_y  \n",
       "0    58.445547  2.736025  28.018920  25.282896  0.902351    59.209990  \n",
       "1    55.058887  2.453842  30.566341  28.112499  0.919721    56.238330  \n",
       "2    59.736680  3.161741  33.555256  30.393514  0.905775    58.828340  \n",
       "3    59.540007  2.555430  30.113990  27.558560  0.915141    59.872505  \n",
       "4    57.841113  3.449657  35.989704  32.540047  0.904149    58.266665  \n",
       "\n",
       "[5 rows x 127 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'Num rows: {features.shape[0]}\\nNum columns: {features.shape[1]}')\n",
    "display(features.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up x\n",
    "x_train = features.iloc[:,3:]\n",
    "\n",
    "# Set up multiple y's\n",
    "y_train = features.iloc[:,2]\n",
    "y_train_binary = y_train > 0\n",
    "y_train_012 = y_train.copy().astype('object')\n",
    "y_train_012[y_train_012 >= 2] = '2+'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate spearman rank correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run spearman correlations for all continous features\n",
    "spearman_correlations = x_train.apply(lambda f: spearman_rank(feature=f, target=y_train), axis=0).rename('correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance and MAD\n",
    "Features with higher variance typically have higher discriminatory power. Conversely, if a variable has 0 variance, it cannot discriminate the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate variances\n",
    "variances = x_train.var(axis=0).rename('variance')\n",
    "#variances.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MAD\n",
    "mads = x_train.apply(lambda x: np.mean(np.abs(x - np.mean(x))), axis=0).rename('MAD')\n",
    "#mads.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate difference in mean/med btw target levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_means = x_train.apply(lambda f: diff_in_means(feature=f, target=y_train_binary), axis=0).sort_values(ascending=False, key=abs).rename('diff_mean')\n",
    "#diff_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_medians= x_train.apply(lambda f: diff_in_medians(feature=f, target=y_train_binary), axis=0).sort_values(ascending=False, key=abs).rename('diff_med')\n",
    "#diff_medians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate into 1 dataframe\n",
    "filter_method_results = pd.concat([spearman_correlations, diff_means, diff_medians, variances, mads], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "filter_method_results.to_csv('./continuous_filter_methods.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation matrix (between features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations\n",
    "correlation_matrix = x_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "correlation_matrix.to_csv('continuous_correlations.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, col in enumerate(x_train.columns):\n",
    "    # Open PDF file\n",
    "    with PdfPages(f'../feature_plots/{col}.pdf') as pdf_pages:\n",
    "         # First plot\n",
    "        fig1 = plt.figure(i)\n",
    "        boxplot(x_train[col], y_train_binary)\n",
    "        pdf_pages.savefig(fig1)\n",
    "\n",
    "        # Second plot\n",
    "        fig1 = plt.figure(i)\n",
    "        boxplot(x_train[col], y_train_012)\n",
    "        pdf_pages.savefig(fig1)\n",
    "\n",
    "        # Third plot\n",
    "        fig2 = plt.figure(i)\n",
    "        density_plot(x_train[col], y_train_binary)\n",
    "        pdf_pages.savefig(fig2)\n",
    "\n",
    "        # Fourth plot\n",
    "        fig3 = plt.figure(i)\n",
    "        density_plot(x_train[col], y_train_012)\n",
    "        pdf_pages.savefig(fig2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
